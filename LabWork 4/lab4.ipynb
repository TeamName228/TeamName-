{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3224b480-d81b-44c9-975d-d7d8b2abe4f1",
   "metadata": {},
   "source": [
    "Формулировка лаб4: \n",
    "\n",
    "Для датасета с отзывами с маркетплейса на русском языке (https://github.com/sismetanin/rureviews) построить модель для предсказания тональности текста.\n",
    "\n",
    "1. Использовать как минимум 3 модели машинного обучения, решающие задачу классификации (количество классов определить по анализу датасета)\n",
    "2. Предсказать тональность при помощи NLP-моделей (deeppavlov, natasha и т.д.) \n",
    "3. Определить метрики качества моделей и сравнить полученные результаты, в ячейке markdown представить выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a270e10c-1242-47ff-95ac-d80a9530f385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  качество плохое пошив ужасный (горловина напер...  negative\n",
      "1  Товар отдали другому человеку, я не получила п...  negative\n",
      "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n",
      "3  товар не пришел, продавец продлил защиту без м...  negative\n",
      "4      Кофточка голая синтетика, носить не возможно.  negative\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from deeppavlov import build_model, configs\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('datasets/women-clothing-accessories.3-class.balanced.csv', encoding=\"utf-8\", engine='python', sep='\\t')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efca4365-11d6-463e-8f45-3654f75d4411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Проверка на наличие пропущенных значений\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84074381-cc8c-4c26-bf24-a9a672dadacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    30000\n",
      "neautral    30000\n",
      "positive    30000\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Анализ распределения классов\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a1931f-22fa-4728-8917-821bed0d86bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Векторизация текста с использованием TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926d430-b46f-47bc-b495-32e72432c684",
   "metadata": {},
   "source": [
    "Обучение моделей машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61ed81-b84f-445d-8b4a-bdb29334ebb0",
   "metadata": {},
   "source": [
    "Модель 1: Наивный Байес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0061b59-71f3-43a8-9d4c-40c3e4640729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7137222222222223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.60      0.67      0.63      6060\n",
      "    negative       0.72      0.63      0.67      5942\n",
      "    positive       0.85      0.83      0.84      5998\n",
      "\n",
      "    accuracy                           0.71     18000\n",
      "   macro avg       0.72      0.71      0.72     18000\n",
      "weighted avg       0.72      0.71      0.72     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели Наивного Байеса\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Оценка качества модели\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328be620-75ab-4a7e-a217-421d4fd3edd5",
   "metadata": {},
   "source": [
    "Модель 2: Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b06aec-6329-443c-b6be-23eaca4951a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7403333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.63      0.65      0.64      6060\n",
      "    negative       0.73      0.72      0.72      5942\n",
      "    positive       0.87      0.85      0.86      5998\n",
      "\n",
      "    accuracy                           0.74     18000\n",
      "   macro avg       0.74      0.74      0.74     18000\n",
      "weighted avg       0.74      0.74      0.74     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели Логистической регрессии\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Оценка качества модели\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9407dd4-591d-45a3-9f86-3b79773929b1",
   "metadata": {},
   "source": [
    "Модель 3: Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdb862e-f6ba-46be-858d-c67063a913be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.61      0.64      0.62      6060\n",
      "    negative       0.73      0.68      0.71      5942\n",
      "    positive       0.82      0.83      0.83      5998\n",
      "\n",
      "    accuracy                           0.72     18000\n",
      "   macro avg       0.72      0.72      0.72     18000\n",
      "weighted avg       0.72      0.72      0.72     18000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели Случайного леса\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Оценка качества модели\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc772f-06d2-4cc3-b7e9-c6ddbd13e03d",
   "metadata": {},
   "source": [
    "Использование NLP-моделей для предсказания тональности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840082b4-103e-43e2-9ff8-7cef078a0393",
   "metadata": {},
   "source": [
    "Модель DeepPavlov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5bc9e8a-5e88-4d12-a26c-f91a13033b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-15 15:34:14.625 INFO in 'deeppavlov.core.data.utils'['utils'] at line 97: Downloading from http://files.deeppavlov.ai/v1/classifiers/rusentiment_bert/rusentiment_bert_torch.tar.gz to C:\\Users\\One__\\.deeppavlov\\models\\classifiers\\rusentiment_bert_torch.tar.gz\n",
      "100%|██████████| 1.34G/1.34G [00:33<00:00, 40.0MB/s]\n",
      "2025-03-15 15:34:48.597 INFO in 'deeppavlov.core.data.utils'['utils'] at line 284: Extracting C:\\Users\\One__\\.deeppavlov\\models\\classifiers\\rusentiment_bert_torch.tar.gz archive into C:\\Users\\One__\\.deeppavlov\\models\\classifiers\\rusentiment_bert_torch\n",
      "C:\\Users\\One__\\anaconda3\\envs\\deeppavlov\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeff662669eb4b8e8a855158b10804c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\One__\\anaconda3\\envs\\deeppavlov\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\One__\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77fbaf1ac1442eaa46e31f3a39457b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb61c00f9b3d4003831aa976d904af77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df90cb09950c491cbffcbd5d361e0bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bc5c714e994581a6d3ac854a9e2cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-03-15 15:35:29.561 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 96: Unable to place component TorchTransformersClassifierModel on GPU, since no CUDA GPUs are available. Using CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepPavlov Accuracy: 0.3244444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.00      0.00      0.00      6060\n",
      "    negative       0.58      0.35      0.44      5942\n",
      "     neutral       0.00      0.00      0.00         0\n",
      "    positive       0.63      0.62      0.63      5998\n",
      "        skip       0.00      0.00      0.00         0\n",
      "      speech       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.32     18000\n",
      "   macro avg       0.20      0.16      0.18     18000\n",
      "weighted avg       0.40      0.32      0.35     18000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\One__\\anaconda3\\envs\\deeppavlov\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\One__\\anaconda3\\envs\\deeppavlov\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\One__\\anaconda3\\envs\\deeppavlov\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\One__\\anaconda3\\envs\\deeppavlov\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\One__\\anaconda3\\envs\\deeppavlov\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\One__\\anaconda3\\envs\\deeppavlov\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели DeepPavlov для анализа тональности\n",
    "sentiment_model = build_model(configs.classifiers.rusentiment_bert, download=True)\n",
    "\n",
    "# Предсказание тональности для тестовых данных\n",
    "y_pred_dp = [sentiment_model([text])[0] for text in X_test]\n",
    "\n",
    "# Оценка качества модели\n",
    "print(\"DeepPavlov Accuracy:\", accuracy_score(y_test, y_pred_dp))\n",
    "print(classification_report(y_test, y_pred_dp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195496f4-11f5-4a0f-8ba7-42d22c9ff19d",
   "metadata": {},
   "source": [
    "Оценка качества моделей и сравнение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b874247-3a48-4f67-af80-5c38905bc244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: 0.7137\n",
      "Logistic Regression: 0.7403\n",
      "Random Forest: 0.7185\n",
      "DeepPavlov: 0.3244\n"
     ]
    }
   ],
   "source": [
    "# Сравнение результатов\n",
    "results = {\n",
    "    'Naive Bayes': accuracy_score(y_test, y_pred_nb),\n",
    "    'Logistic Regression': accuracy_score(y_test, y_pred_lr),\n",
    "    'Random Forest': accuracy_score(y_test, y_pred_rf),\n",
    "    'DeepPavlov': accuracy_score(y_test, y_pred_dp)\n",
    "}\n",
    "\n",
    "for model, accuracy in results.items():\n",
    "    print(f\"{model}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdc73ab-56a2-4094-8795-16c22529c9a8",
   "metadata": {},
   "source": [
    "Вывод:\n",
    "\n",
    "1.Модель Logistic Regression показала наилучшую точность среди классических моделей машинного обучения.\n",
    "2.Random Forest и Naive Bayes показали несколько худшие результаты, но все же остаются достаточно эффективными для данной задачи.\n",
    "3.Модель DeepPavlov  показала наихудшую точность, ее предсказания при применении к отзывам оказались не столь эффективными."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
