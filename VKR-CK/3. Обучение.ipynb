{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6069a587-a7f8-45f4-837d-92e1b6f2fa02",
   "metadata": {},
   "source": [
    "hasyv2/hasyv2/hasy-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68202691-0620-4674-958a-e9e72a695e6c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/enovo/hasy-env/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /home/enovo/hasy-env/lib/python3.10/site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: pillow in /home/enovo/hasy-env/lib/python3.10/site-packages (11.0.0)\n",
      "Requirement already satisfied: numpy in /home/enovo/hasy-env/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/enovo/hasy-env/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: scikit-learn in /home/enovo/hasy-env/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: opencv-python in /home/enovo/hasy-env/lib/python3.10/site-packages (4.11.0.86)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: filelock in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/enovo/hasy-env/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/enovo/hasy-env/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/enovo/hasy-env/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/enovo/hasy-env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/enovo/hasy-env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/enovo/hasy-env/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/enovo/hasy-env/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/enovo/hasy-env/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/enovo/hasy-env/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/enovo/hasy-env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/enovo/hasy-env/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision pillow numpy pandas scikit-learn opencv-python tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4589016-a353-40b1-9606-aa4822232ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормализованный диапазон symbol_id: [0, 368]\n",
      "Количество уникальных классов: 369\n",
      "✅ Словарь сохранён в model/class_to_symbol_normalized.json\n",
      "✅ Тестовые изображения сохранены в test_formatted\n",
      "✅ Данные загружены: 134586 обучающих, 33647 тестовых образцов\n",
      "✅ Модель на cuda\n",
      "✅ Загружена предобученная модель из models/hasyv2_model_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|███████████████████████████████████████████████████| 2103/2103 [00:26<00:00, 80.33batch/s, loss=2.4932]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Average Loss: 2.0726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 191.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6531 (21976/33647), Top-5 точность: 0.9433\n",
      "✅ Сохранена лучшая модель с точностью 0.6531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|███████████████████████████████████████████████████| 2103/2103 [00:26<00:00, 80.76batch/s, loss=1.6368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Average Loss: 1.8752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 189.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6432 (21643/33647), Top-5 точность: 0.9460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|███████████████████████████████████████████████████| 2103/2103 [00:25<00:00, 83.69batch/s, loss=1.4906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Average Loss: 1.7939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 192.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6677 (22467/33647), Top-5 точность: 0.9543\n",
      "✅ Сохранена лучшая модель с точностью 0.6677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|███████████████████████████████████████████████████| 2103/2103 [00:25<00:00, 82.28batch/s, loss=2.1400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Average Loss: 1.7483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 191.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6450 (21703/33647), Top-5 точность: 0.9495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|███████████████████████████████████████████████████| 2103/2103 [00:25<00:00, 82.31batch/s, loss=1.5528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Average Loss: 1.6975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 189.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6614 (22255/33647), Top-5 точность: 0.9561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|███████████████████████████████████████████████████| 2103/2103 [00:25<00:00, 83.09batch/s, loss=1.1407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Average Loss: 1.6701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 191.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6774 (22791/33647), Top-5 точность: 0.9540\n",
      "✅ Сохранена лучшая модель с точностью 0.6774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|███████████████████████████████████████████████████| 2103/2103 [00:25<00:00, 81.84batch/s, loss=1.8061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Average Loss: 1.6410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 196.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6865 (23097/33647), Top-5 точность: 0.9530\n",
      "✅ Сохранена лучшая модель с точностью 0.6865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|███████████████████████████████████████████████████| 2103/2103 [00:24<00:00, 84.71batch/s, loss=1.6802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Average Loss: 1.6325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 193.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6663 (22419/33647), Top-5 точность: 0.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|███████████████████████████████████████████████████| 2103/2103 [00:25<00:00, 84.11batch/s, loss=1.6401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Average Loss: 1.6032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 192.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6940 (23351/33647), Top-5 точность: 0.9573\n",
      "✅ Сохранена лучшая модель с точностью 0.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████████████████████████████████████████████| 2103/2103 [00:24<00:00, 85.24batch/s, loss=1.7468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Average Loss: 1.5936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 190.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6850 (23048/33647), Top-5 точность: 0.9583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████████████████████████████████████████████| 2103/2103 [00:25<00:00, 83.41batch/s, loss=1.3293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Average Loss: 1.5839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 191.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6780 (22814/33647), Top-5 точность: 0.9595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████████████████████████████████████████████| 2103/2103 [00:24<00:00, 85.23batch/s, loss=1.8569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Average Loss: 1.5674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 191.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6898 (23209/33647), Top-5 точность: 0.9607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████████████████████████████████████████████| 2103/2103 [00:24<00:00, 84.45batch/s, loss=1.6849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Average Loss: 1.5633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 194.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6916 (23271/33647), Top-5 точность: 0.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████████████████████████████████████████████| 2103/2103 [00:24<00:00, 86.37batch/s, loss=1.4694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Average Loss: 1.5535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 194.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6864 (23095/33647), Top-5 точность: 0.9592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████████████████████████████████████████████| 2103/2103 [00:24<00:00, 85.82batch/s, loss=1.4135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Average Loss: 1.5467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 193.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6993 (23529/33647), Top-5 точность: 0.9595\n",
      "✅ Сохранена лучшая модель с точностью 0.6993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████████████████████████████████████████████| 2103/2103 [00:24<00:00, 86.38batch/s, loss=1.9368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Average Loss: 1.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 193.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6840 (23015/33647), Top-5 точность: 0.9568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████████████████████████████████████████████| 2103/2103 [00:26<00:00, 79.32batch/s, loss=1.9038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Average Loss: 1.5228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 191.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6723 (22622/33647), Top-5 точность: 0.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████████████████████████████████████████████| 2103/2103 [00:25<00:00, 81.64batch/s, loss=1.3692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Average Loss: 1.5276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 193.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6852 (23055/33647), Top-5 точность: 0.9630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████████████████████████████████████████████| 2103/2103 [00:26<00:00, 79.26batch/s, loss=1.2434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Average Loss: 1.5148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 185.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6819 (22944/33647), Top-5 точность: 0.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████████████████████████████████████████████| 2103/2103 [00:26<00:00, 79.10batch/s, loss=1.2985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Average Loss: 1.5103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 526/526 [00:02<00:00, 190.19batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.6857 (23071/33647), Top-5 точность: 0.9595\n",
      "✅ Обучение завершено. Лучшая точность: 0.6993, Лучшая Top-5 точность: 0.9595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.amp import GradScaler, autocast\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Кастомный датасет ---\n",
    "class HASYv2Dataset(Dataset):\n",
    "    def __init__(self, df, images_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.basename(self.df.iloc[idx]['path'])\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('L')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Файл не найден: {img_path}\")\n",
    "            raise\n",
    "        label = self.df.iloc[idx]['normalized_symbol_id']\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# --- Улучшенная CNN ---\n",
    "class EnhancedSymbolCNN(nn.Module):\n",
    "    def __init__(self, num_classes=369):\n",
    "        super(EnhancedSymbolCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# --- Тест форматирования ---\n",
    "def test_formatting(dataset, output_dir='test_formatted'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i in range(min(5, len(dataset))):\n",
    "        # Получаем исходное изображение без трансформации\n",
    "        img_name = os.path.basename(dataset.df.iloc[i]['path'])\n",
    "        img_path = os.path.join(dataset.images_dir, img_name)\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        label = dataset.df.iloc[i]['normalized_symbol_id']\n",
    "\n",
    "        # Применяем бинаризацию и инверсию\n",
    "        img_np = np.array(img)\n",
    "        _, img_np = cv2.threshold(img_np, 128, 255, cv2.THRESH_BINARY)\n",
    "        img_np = 255 - img_np  # Инверсия для черного фона и белого символа\n",
    "        img_pil = Image.fromarray(img_np.astype(np.uint8))\n",
    "        img_pil.save(os.path.join(output_dir, f'test_{i}_label_{label}.png'))\n",
    "    print(f\"✅ Тестовые изображения сохранены в {output_dir}\")\n",
    "\n",
    "# --- Основная функция обучения ---\n",
    "def main():\n",
    "    # Загрузка CSV\n",
    "    csv_path = 'hasyv2/hasyv2/hasy-data-labels.csv'\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Нормализация symbol_id\n",
    "    unique_symbol_ids = sorted(df['symbol_id'].unique())\n",
    "    id_to_normalized = {old_id: new_id for new_id, old_id in enumerate(unique_symbol_ids)}\n",
    "    if len(unique_symbol_ids) != 369:\n",
    "        raise ValueError(f\"Ожидалось 369 уникальных классов, найдено {len(unique_symbol_ids)}\")\n",
    "    df['normalized_symbol_id'] = df['symbol_id'].map(id_to_normalized)\n",
    "    print(f\"Нормализованный диапазон symbol_id: [{df['normalized_symbol_id'].min()}, {df['normalized_symbol_id'].max()}]\")\n",
    "    print(f\"Количество уникальных классов: {len(df['normalized_symbol_id'].unique())}\")\n",
    "\n",
    "    # Обновление словаря class_to_symbol\n",
    "    with open('hasyv2/hasyv2/symbols.csv', 'r', encoding='utf-8') as f:\n",
    "        symbols_df = pd.read_csv(f)\n",
    "    class_to_symbol = {}\n",
    "    for index, row in symbols_df.iterrows():\n",
    "        class_id = row['symbol_id']\n",
    "        latex_command = row['latex']\n",
    "        class_to_symbol[str(id_to_normalized[class_id])] = latex_command\n",
    "    with open('model/class_to_symbol_normalized.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(class_to_symbol, f, ensure_ascii=False, indent=4)\n",
    "    print(\"✅ Словарь сохранён в model/class_to_symbol_normalized.json\")\n",
    "\n",
    "    # Разделение данных\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    images_dir = 'hasyv2/hasyv2/hasy-data'\n",
    "\n",
    "    # Аугментация данных с небелыми фонами\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1),  # Нерегулярные фоны\n",
    "        transforms.RandomGrayscale(p=0.5),  # Случайно серые изображения\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "        transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: 1 - x if torch.rand(1).item() > 0.5 else x),  # Случайная инверсия после ToTensor\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "        transforms.RandomErasing(p=0.5, scale=(0.02, 0.1)),\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ])\n",
    "\n",
    "    # Создание датасетов\n",
    "    train_dataset = HASYv2Dataset(train_df, images_dir, transform=train_transform)\n",
    "    test_dataset = HASYv2Dataset(test_df, images_dir, transform=test_transform)\n",
    "\n",
    "    # Тест форматирования\n",
    "    test_formatting(train_dataset)\n",
    "\n",
    "    # Вычисление классовых весов\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(df['normalized_symbol_id']),\n",
    "                                        y=df['normalized_symbol_id'])\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "    # Создание загрузчиков\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True, num_workers=4)\n",
    "    print(f\"✅ Данные загружены: {len(train_dataset)} обучающих, {len(test_dataset)} тестовых образцов\")\n",
    "\n",
    "    # Инициализация модели\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = EnhancedSymbolCNN(num_classes=369).to(device)\n",
    "    print(f\"✅ Модель на {device}\")\n",
    "\n",
    "    # Загрузка предобученной модели, если существует\n",
    "    model_path = 'models/hasyv2_model_best.pth'\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "        print(f\"✅ Загружена предобученная модель из {model_path}\")\n",
    "\n",
    "    # Оптимизатор и функция потерь\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Обучение\n",
    "    num_epochs = 20\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch')\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "        # Оценка\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        top5_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(test_loader, desc='Evaluating', unit='batch'):\n",
    "                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                    outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                # Top-5 accuracy\n",
    "                _, top5_pred = outputs.topk(5, dim=1)\n",
    "                top5_correct += top5_pred.eq(labels.view(-1, 1).expand_as(top5_pred)).sum().item()\n",
    "        accuracy = correct / total\n",
    "        top5_accuracy = top5_correct / total\n",
    "        print(f'Точность на тестовой выборке: {accuracy:.4f} ({correct}/{total}), Top-5 точность: {top5_accuracy:.4f}')\n",
    "\n",
    "        # Сохранение модели после каждой эпохи\n",
    "        torch.save(model.state_dict(), f'model/hasyv2_model_epoch_{epoch + 1}.pth')\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), 'model/hasyv2_model_arg.pth')\n",
    "            print(f\"✅ Сохранена лучшая модель с точностью {accuracy:.4f}\")\n",
    "\n",
    "    print(f\"✅ Обучение завершено. Лучшая точность: {best_accuracy:.4f}, Лучшая Top-5 точность: {top5_accuracy:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c700194-e4dd-484b-8667-ab89c2203b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# y_true — реальные метки, y_pred — предсказания\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='viridis', values_format='d')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab19e0-6760-4dc5-b055-92984c76ae4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
