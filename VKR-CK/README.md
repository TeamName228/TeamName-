# **Распознавание рукописных математических символов**

## **Содержание**

[•	Команда NoComments](#title1)<p><p/>
[•	Практическая значимость проекта](#title2)<p></p>
[•	Цель работы](#title3)<p></p>
[•	Стек технологий](#title4)<p></p>
[•	Библиотеки](#title5)<p></p>
[•	Архитектура модели](#title6)<p></p>
[•	Загрузка и предобработка данных](#title7)<p></p>
[•	Набор данных HASYv2](#title8)<p></p>
[•	Настройка обучения HASYv2](#title9)<p></p>
[•	Процесс обучения включал](#title10)<p></p>
[•	Ссылки](#title11)<p></p>

## <a id="title1">Команда NoComments</a>

<p>Реализовали приложение рукописных математических символов студенты группы АУБП-23:</p>
<dl><dd><dl><dd>
<p>•	Газизов Айрат Рамисович</p>
<p>•	Конобеевских Андрей Васильевич</p>
<p>•	Игнатова Александра Руслановна</p>
<p>•	Ермаков Александр Андреевич</p>
<p>•	Монахов Иван Алексеевич</p>
</dd></dl></dd></dl>

## <a id="title2">Практическая значимость проекта</a>

<dl><dd><dl><dd>
<p>•	Автоматизация обработки рукописных заметок (например, в образовании для проверки задач).</p>
<p>•	Цифровизация научных и инженерных записей (распознавание математических символов из формул из конспектов, чертежей).</p>
</dd></dl></dd></dl>

## <a id="title3">Цель работы</a>

<p>Разработать нейросетевую модель, способную автоматически распознавать рукописные математические символы и
преобразовывать их в редактируемый цифровой текст с сохранением структуры формулы.</p>

## <a id="title4">Стек технологий</a>

<dl><dd><dl><dd>
<p>•	Язык программирования: Python</p>
<p>•	Среда: Jupyter Notebook</p>
<p>•	Операционная система: WSL (Windows Subsystem for Linux) с Ubuntu</p>
<p>•	Обработка данных: pandas, numpy</p>
<p>•	Обработка изображений: PIL, OpenCV (cv2)</p>
<p>•	Глубокое обучение: PyTorch (torch, torch.nn, torch.optim, torchvision.transforms, torch.amp, torch.optim.lr_scheduler), CUDA</p>
<p>•	Машинное обучение: scikit-learn (train_test_split, compute_class_weight)</p>
<p>•	Мониторинг: tqdm</p>
<p>•	Визуализация: matplotlib</p>
<p>•	Работа с файлами: json, os, zipfile</p>
<p>•	Конвертация LaTeX: pylatexenc</p>
<p>•	Анализ модели: torchsummary</p>
</dd></dl></dd></dl>

## <a id="title5">Библиотеки</a>

<p>Для работы с данными, обработки изображений и отображения прогресса обучения, используются такие библиотеки, как:</p>

<dl><dd><dl><dd>
<p>•	torch</p>
<p>•	torchvision</p>
<p>•	pandas</p>
<p>•	numpy</p>
<p>•	opencv-python</p>
<p>•	pandas, numpy</p>
<p>•	PIL</p>
<p>•	torch</p>
<p>•	torchvision</p>
<p>•	sklearn</p>
<p>•	tqdm</p>
</dd></dl></dd></dl>

## <a id="title6">Архитектура модели</a>

<p>Модель EnhancedSymbolCNN была разработана как CNN для классификации символов. Ее структура включает:</p>
  <dl><dd><dl><dd>
  <p>•	Сверточные слои:</p>
      <dl><dd><dl><dd>
      <p>Три блока, каждый из которых содержит два слоя Conv2d с увеличивающимся числом фильтров (32, 64, 128), за которыми следуют BatchNorm2d, активация ReLU и MaxPool2d 
      (размер ядра     2, шаг 2). Ядра имеют размер 3x3 с паддингом 1.</p>
      </dd></dl></dd></dl>
  <p>•	Классификационные слои:</p>
    <dl><dd><dl><dd>
     <p>После сверток данные проходят через последовательность полносвязных слоев:</p>
      <dl><dd><dl><dd>
        <p>o	Линейный слой (128 * 4 * 4 → 1024) с ReLU и dropout (0.5).</p>
        <p>o	Линейный слой (1024 → 512) с ReLU и dropout (0.5).</p>
        <p>o	Финальный линейный слой (512 → 369) для классификации на 369 классов.</p>
        </dd></dl></dd></dl>
      </dd></dl></dd></dl>
  <p>•	Параметры: Модель содержит около 3,1 миллиона параметров, что подтверждено выводом torchsummary.</p>
  <p>•	Устройство: Модель обучалась на CUDA, если доступен GPU, иначе на CPU, с использованием смешанной точности (torch.amp) для повышения эффективности.</p>
  </dd></dl></dd></dl>

## <a id="title7">Загрузка и предобработка данных</a>

<dl><dd><dl><dd>
<p>•  Данные загружаются из CSV-файла (hasyv2/hasyv2/hasy-data-labels.csv) и директории с изображениями (hasyv2/hasyv2/hasy-data).</p>
<p>•  Идентификаторы символов нормализуются в диапазон от 0 до 368, создается словарь, отображающий нормализованные ID на LaTeX-команды, и сохраняется как model/class_to_symbol_normalized.json.</p>
<p>•  Данные разделяются на обучающую (80%) и тестовую (20%) выборки с помощью train_test_split из sklearn.</p>
</dd></dl></dd></dl>

## <a id="title8">Набор данных HASYv2</a>

<p>Определен класс HASYv2Dataset для работы с данными.</p>
<p>Применяются трансформации через torchvision.transforms, включая изменение размера изображений до 32x32, цветовую джиттер, случайное преобразование в градации серого, поворот, аффинные преобразования, перспективные искажения, инверсию, нормализацию и случайное стирание для повышения устойчивости модели.</p>

![image](https://github.com/user-attachments/assets/fa98c642-5433-4181-8335-01b93ce8e07e)

## <a id="title9">Настройка обучения HASYv2</a>

<dl><dd><dl><dd>
<p>•  Модель инициализируется и перемещается на GPU, если доступен.</p>
<p>•  Если существует предобученная модель (hasyv2_model_best.pth), загружаются ее веса для продолжения дообучения.</p>
<p>•  Используется функция потерь CrossEntropyLoss с весами классов для учета дисбаланса.</p>
<p>•  Оптимизатор Adam с learning rate 0.001 и weight decay для регуляризации.</p>
<p>•  Включено обучение с смешанной точностью (torch.amp) для ускорения на GPU.</p>
</dd></dl></dd></dl>

## <a id="title10">Процесс обучения включал</a>

<p>Процесс обучения состоял из двух фаз: первичного обучения и дообучения:</p>

<dl><dd><dl><dd>
•  Первичное обучение на 20 эпохах с точностью 69,93% (top-1) и 95,95% (top-5).
•  Дообучение на 50 эпохах, улучшив точность до 73,08% (top-1) и 96,87% (top-5).
</dd></dl></dd></dl>

## <a id="title11">Ссылки</a>

<p>Веб-реализация модели - https://disk.yandex.ru/d/SbM8_t1Q38prAA</p>
